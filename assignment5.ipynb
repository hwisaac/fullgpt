{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 14:52:44.446 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /Users/hwang-isaac/.pyenv/versions/fullgpt/lib/python3.11/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-03-25 14:52:44.446 Session state does not function when running a script without `streamlit run`\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'st.session_state has no key \"uploaded_file\". Did you forget to initialize it? More info: https://docs.streamlit.io/library/advanced-features/session-state#initialization'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/fullgpt/lib/python3.11/site-packages/streamlit/runtime/state/session_state.py:394\u001b[0m, in \u001b[0;36mSessionState.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 394\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/fullgpt/lib/python3.11/site-packages/streamlit/runtime/state/session_state.py:439\u001b[0m, in \u001b[0;36mSessionState._getitem\u001b[0;34m(self, widget_id, user_key)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;66;03m# We'll never get here\u001b[39;00m\n\u001b[0;32m--> 439\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 121\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# 파일 업로드 후 벡터 스토어 생성\u001b[39;00m\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muploaded_file\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m openai_api_key:\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m st\u001b[38;5;241m.\u001b[39msession_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvectorstore\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    123\u001b[0m         st\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m문서를 벡터 스토어로 변환 중입니다...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/fullgpt/lib/python3.11/site-packages/streamlit/runtime/state/session_state_proxy.py:90\u001b[0m, in \u001b[0;36mSessionStateProxy.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     88\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(key)\n\u001b[1;32m     89\u001b[0m require_valid_user_key(key)\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_session_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/fullgpt/lib/python3.11/site-packages/streamlit/runtime/state/safe_session_state.py:113\u001b[0m, in \u001b[0;36mSafeSessionState.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_disconnected:\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m--> 113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_state\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/fullgpt/lib/python3.11/site-packages/streamlit/runtime/state/session_state.py:396\u001b[0m, in \u001b[0;36mSessionState.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem(widget_id, key)\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 396\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(_missing_key_error_message(key))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'st.session_state has no key \"uploaded_file\". Did you forget to initialize it? More info: https://docs.streamlit.io/library/advanced-features/session-state#initialization'"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain, StuffDocumentsChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import openai\n",
    "import tempfile\n",
    "\n",
    "# 스트림릿 페이지 설정\n",
    "st.set_page_config(page_title=\"RAG with Streamlit\", page_icon=\":books:\")\n",
    "\n",
    "# 사이드바: OpenAI API 키 입력\n",
    "st.sidebar.title(\"설정\")\n",
    "openai_api_key = st.sidebar.text_input(\"OpenAI API Key를 입력하세요\", type=\"password\")\n",
    "if openai_api_key:\n",
    "    openai.api_key = openai_api_key\n",
    "\n",
    "# 사이드바: 깃허브 링크\n",
    "st.sidebar.markdown(\"### Github Repo\")\n",
    "st.sidebar.markdown(\"[프로젝트 깃허브 링크](https://github.com/your-repo-url)\")\n",
    "\n",
    "# 페이지 헤더\n",
    "st.title(\"RAG 파이프라인 데모 - 1984 소설 예시\")\n",
    "\n",
    "# 세션 스테이트 초기화\n",
    "if \"memory\" not in st.session_state:\n",
    "    st.session_state[\"memory\"] = ConversationBufferMemory(\n",
    "        memory_key=\"chat_history\", input_key=\"question\",\n",
    "    )\n",
    "if \"vectorstore\" not in st.session_state:\n",
    "    st.session_state[\"vectorstore\"] = None\n",
    "if \"uploaded_file\" not in st.session_state:\n",
    "    st.session_state[\"uploaded_file\"] = None\n",
    "\n",
    "# 파일 업로드\n",
    "uploaded_file = st.file_uploader(\n",
    "    \"문서 파일을 업로드하세요 (예: 1984 일부 텍스트)\", type=[\"txt\"]\n",
    ")\n",
    "if uploaded_file is not None:\n",
    "    st.session_state[\"uploaded_file\"] = uploaded_file\n",
    "\n",
    "\n",
    "# 벡터 스토어 생성\n",
    "def create_vectorstore(file):\n",
    "    # 임시 파일로 저장\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".txt\") as tmp_file:\n",
    "        tmp_file.write(file.read())\n",
    "        tmp_file_path = tmp_file.name\n",
    "\n",
    "    loader = UnstructuredFileLoader(tmp_file_path)\n",
    "    documents = loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    splits = text_splitter.split_documents(documents)\n",
    "\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vectorstore = FAISS.from_documents(splits, embeddings)\n",
    "    return vectorstore\n",
    "\n",
    "\n",
    "# 문서를 기반으로 RAG 체인 구성 함수\n",
    "def build_rag_chain():\n",
    "    # 프롬프트 템플릿\n",
    "    prompt_template = \"\"\"\n",
    "당신은 George Orwell의 1984 소설에 관한 질문에 답변하는 도우미입니다.\n",
    "주어진 문맥 정보를 기반으로만 답변하고, 문맥 정보에서 발견할 수 없는 내용은 \"문맥 정보에서 찾을 수 없습니다\"라고 대답하세요.\n",
    "\n",
    "문맥 정보:\n",
    "{context}\n",
    "\n",
    "이전 대화:\n",
    "{chat_history}\n",
    "\n",
    "질문: {question}\n",
    "답변:\n",
    "\"\"\"\n",
    "    document_prompt = PromptTemplate(\n",
    "        input_variables=[\"page_content\"], template=\"{page_content}\"\n",
    "    )\n",
    "    prompt = PromptTemplate(\n",
    "        template=prompt_template,\n",
    "        input_variables=[\"context\", \"question\", \"chat_history\"],\n",
    "    )\n",
    "\n",
    "    # LLM 설정 (모델명은 필요에 따라 수정하세요)\n",
    "    llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "    # LLMChain\n",
    "    llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "    # StuffDocumentsChain\n",
    "    stuff_chain = StuffDocumentsChain(\n",
    "        llm_chain=llm_chain,\n",
    "        document_variable_name=\"context\",\n",
    "        document_prompt=document_prompt,\n",
    "    )\n",
    "    return stuff_chain\n",
    "\n",
    "\n",
    "def ask_question(question):\n",
    "    if st.session_state[\"vectorstore\"] is None:\n",
    "        return \"먼저 문서를 업로드해 주세요.\"\n",
    "\n",
    "    retriever = st.session_state[\"vectorstore\"].as_retriever()\n",
    "    docs = retriever.get_relevant_documents(question)\n",
    "\n",
    "    # 메모리에서 채팅 기록 가져오기\n",
    "    chat_history = st.session_state[\"memory\"].load_memory_variables({})[\"chat_history\"]\n",
    "\n",
    "    # StuffDocumentsChain 실행\n",
    "    stuff_chain = build_rag_chain()\n",
    "    response = stuff_chain.run(\n",
    "        input_documents=docs, question=question, chat_history=chat_history\n",
    "    )\n",
    "\n",
    "    # 메모리 업데이트\n",
    "    st.session_state[\"memory\"].save_context(\n",
    "        {\"question\": question}, {\"output\": response}\n",
    "    )\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "# 파일 업로드 후 벡터 스토어 생성\n",
    "if st.session_state[\"uploaded_file\"] is not None and openai_api_key:\n",
    "    if st.session_state[\"vectorstore\"] is None:\n",
    "        st.write(\"문서를 벡터 스토어로 변환 중입니다...\")\n",
    "        st.session_state[\"vectorstore\"] = create_vectorstore(\n",
    "            st.session_state[\"uploaded_file\"]\n",
    "        )\n",
    "        st.success(\"벡터 스토어 생성 완료!\")\n",
    "\n",
    "# 사용자 질문 입력\n",
    "question = st.text_input(\"질문을 입력하세요:\", \"\")\n",
    "if st.button(\"질문하기\"):\n",
    "    if not openai_api_key:\n",
    "        st.warning(\"OpenAI API Key를 입력해야 합니다.\")\n",
    "    elif st.session_state[\"uploaded_file\"] is None:\n",
    "        st.warning(\"문서 파일을 먼저 업로드해주세요.\")\n",
    "    else:\n",
    "        with st.spinner(\"답변 생성 중...\"):\n",
    "            answer = ask_question(question)\n",
    "        st.write(\"**Q:**\", question)\n",
    "        st.write(\"**A:**\", answer)\n",
    "\n",
    "# 이전 대화 히스토리 출력\n",
    "if st.session_state[\"memory\"].buffer:\n",
    "    st.markdown(\"---\")\n",
    "    st.markdown(\"### 대화 기록\")\n",
    "\n",
    "    for i, msg in enumerate(st.session_state[\"memory\"].buffer):\n",
    "        role = \"사용자\" if i % 2 == 0 else \"AI\"\n",
    "        # 각 메시지를 바로 출력\n",
    "        st.write(f\"**{role}**: {msg}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fullgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
